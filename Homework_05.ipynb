{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "wine qualityデータセットを使って、qualityを推論するネットワークを構築"
      ],
      "metadata": {
        "id": "XHZrGxW3bXKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install japanize_matplotlib | tail -n 1\n",
        "!pip install torchviz | tail -n 1\n",
        "!pip install torchinfo | tail -n 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxYq4XvELZAJ",
        "outputId": "40df2709-f45a-409d-e10d-25048dc20ef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed japanize-matplotlib-1.1.3\n",
            "Successfully installed torchviz-0.0.2\n",
            "Successfully installed torchinfo-1.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XK-hBZb3Kx1T"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import japanize_matplotlib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchinfo import summary\n",
        "from torchviz import make_dot\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/221001/winequality-red.csv\")"
      ],
      "metadata": {
        "id": "hOFd9wnCK52d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "2-8ppruv7Rq5",
        "outputId": "f9ccf666-e81f-479d-be83-e2bd2f26bfe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "0            7.4              0.70         0.00             1.9      0.076   \n",
              "1            7.8              0.88         0.00             2.6      0.098   \n",
              "2            7.8              0.76         0.04             2.3      0.092   \n",
              "3           11.2              0.28         0.56             1.9      0.075   \n",
              "4            7.4              0.70         0.00             1.9      0.076   \n",
              "\n",
              "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
              "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
              "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
              "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
              "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
              "\n",
              "   alcohol  quality  \n",
              "0      9.4        5  \n",
              "1      9.8        5  \n",
              "2      9.8        5  \n",
              "3      9.8        6  \n",
              "4      9.4        5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d401cab4-f848-4cb1-a0cc-06f874470080\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d401cab4-f848-4cb1-a0cc-06f874470080')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d401cab4-f848-4cb1-a0cc-06f874470080 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d401cab4-f848-4cb1-a0cc-06f874470080');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]"
      ],
      "metadata": {
        "id": "5oyJKvvJ7V99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.values\n",
        "y = y.values"
      ],
      "metadata": {
        "id": "3rMLpOSi76rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6qHr9Ff8qwp",
        "outputId": "75cfb95a-fff8-4d09-94cf-77226c26c983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1599, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ9VFZIelcJp",
        "outputId": "ce1c937b-967a-4527-d1f6-2c6ba04635f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1599,)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(set(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mwn_jUK-nlKU",
        "outputId": "c91ca55b-759d-4e5c-e7e4-50d46388c611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 4, 5, 6, 7, 8]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ラベルの性質 3, 4, 5→0, 1, 2となるため、それに変換をする\n",
        "y_dict_values = range(0, 6)\n",
        "y_dict_keys = list(set(y))\n",
        "y_dict = dict(zip(y_dict_keys,y_dict_values))"
      ],
      "metadata": {
        "id": "0gzTVpcYnzES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMd2w7KSo1PY",
        "outputId": "d86f5b48-b8ef-4b47-9699-bffd5b4e48da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: 0, 4: 1, 5: 2, 6: 3, 7: 4, 8: 5}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_labels = np.array([])\n",
        "for num in range(len(y)):\n",
        "  work = y[num]\n",
        "  y_label = y_dict[work]\n",
        "  y_labels = np.append(y_labels, y_label)\n"
      ],
      "metadata": {
        "id": "MPe5J6PVpJm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTtyUaRnsMUq",
        "outputId": "b0bbc305-e230-47e9-aba6-6ebb42f39c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 5, 5, ..., 6, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_q9egWzsF73",
        "outputId": "f794a0d1-c94c-4b72-a572-360f26884c5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 2., 2., ..., 3., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y_labels, test_size=0.2)"
      ],
      "metadata": {
        "id": "fAz_qkIs7msu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# パラメータ\n",
        "\n",
        "# 入力次元数\n",
        "n_input = x_train.shape[1]\n",
        "\n",
        "# 出力次元数\n",
        "n_output = len(list(set(y_train)))\n",
        "\n",
        "print(f\"n_input : {n_input} n_output : {n_output}\")"
      ],
      "metadata": {
        "id": "OAocQoOK75T4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "191a275c-8951-4627-cd10-d6db1b9bc8d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_input : 11 n_output : 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデル定義\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self, n_input, n_output):\n",
        "    super().__init__()\n",
        "    self.l1 = nn.Linear(n_input, 20)\n",
        "    self.l2 = nn.Linear(20, 10)\n",
        "    self.l3 = nn.Linear(10, n_output)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    # 値の初期化\n",
        "    self.l1.weight.data.fill_(1.0)\n",
        "    self.l1.bias.data.fill_(1.0)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x1 = self.relu(self.l1(x))\n",
        "    x2 = self.relu(self.l2(x1))\n",
        "    x3 = self.l3(x2)\n",
        "    return x3"
      ],
      "metadata": {
        "id": "uZWB7OxsW3KA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 値のtensor化\n",
        "# ラベルは整数なので、long型\n",
        "inputs_train = torch.tensor(x_train).float()\n",
        "labels_train = torch.tensor(y_train).long()\n",
        "inputs_test = torch.tensor(x_test).float()\n",
        "labels_test = torch.tensor(y_test).long()"
      ],
      "metadata": {
        "id": "vbHjkGWoatFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 繰り返し計算\n",
        "\n",
        "# 学習率\n",
        "lr = 0.0001\n",
        "\n",
        "# インスタンス生成\n",
        "# 初期化\n",
        "net = Net(n_input, n_output)\n",
        "\n",
        "# 損失関数 : 交差エントロピー関数\n",
        "# 線形では、MSELossを使っていた\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化関数 : 勾配降下法\n",
        "optimizer = optim.SGD(net.parameters(), lr = lr)\n",
        "\n",
        "# 繰り返し回数\n",
        "num_epochs = 20000\n",
        "\n",
        "# 評価結果記録用\n",
        "history = np.zeros((0, 5))"
      ],
      "metadata": {
        "id": "Im_Pw_QvZBIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for parameter in net.named_parameters():\n",
        "  print(parameter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXvHam5trEr7",
        "outputId": "3e075098-e37c-4fbf-c147-cbd1fb214ec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('l1.weight', Parameter containing:\n",
            "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], requires_grad=True))\n",
            "('l1.bias', Parameter containing:\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.], requires_grad=True))\n",
            "('l2.weight', Parameter containing:\n",
            "tensor([[-1.2568e-01,  1.9530e-01, -8.8298e-02, -2.2584e-02,  9.0655e-02,\n",
            "          2.1307e-01, -6.3338e-02, -1.2353e-01,  1.5401e-01,  4.8002e-02,\n",
            "          1.7949e-01,  9.5499e-02,  8.4307e-02, -2.0357e-01, -1.2783e-01,\n",
            "          8.5343e-02,  2.7314e-02,  4.5925e-02,  8.9568e-02,  1.7033e-01],\n",
            "        [ 1.5865e-01,  6.5656e-02,  5.9279e-02, -6.5142e-02, -1.5478e-02,\n",
            "          2.2346e-01,  8.6993e-02, -3.4712e-02, -1.1601e-01,  9.7345e-03,\n",
            "          1.4840e-01, -7.3163e-02,  1.7404e-02, -1.1418e-01,  2.7586e-02,\n",
            "         -9.8565e-02, -2.9699e-02, -1.4986e-01, -7.1048e-02, -2.2353e-01],\n",
            "        [ 2.1810e-01,  1.0457e-01,  2.1232e-01,  1.0151e-01,  1.5656e-01,\n",
            "         -1.3408e-01,  1.3352e-01,  1.4172e-01, -9.7006e-02,  1.6785e-01,\n",
            "          3.7845e-03,  8.9925e-02,  1.4618e-01,  8.4144e-02,  8.3011e-03,\n",
            "          1.0998e-01,  1.9558e-01,  2.1376e-01, -1.2396e-02, -2.2142e-01],\n",
            "        [-1.3287e-01, -1.9361e-01, -9.0147e-02,  2.0441e-02, -2.4454e-02,\n",
            "         -3.4189e-02,  1.9500e-01,  7.0115e-03, -2.0641e-01,  1.7849e-01,\n",
            "         -1.9446e-01,  5.2564e-02, -8.9703e-03,  1.7132e-01,  2.1485e-01,\n",
            "          7.9162e-02, -4.5111e-02, -1.1473e-02,  1.7862e-01,  1.4821e-02],\n",
            "        [ 1.5308e-01, -4.9894e-02, -1.2774e-01,  5.9282e-02,  6.5882e-02,\n",
            "         -4.9200e-02, -1.3030e-01, -2.9326e-02, -1.7039e-01,  2.1272e-01,\n",
            "         -9.5240e-02, -1.1747e-01,  1.4154e-01, -7.2701e-02,  6.9796e-02,\n",
            "         -1.6831e-01,  1.8619e-01, -7.2090e-02, -1.9115e-01, -2.0169e-01],\n",
            "        [-4.4910e-02, -2.0687e-01, -8.5997e-02,  6.9312e-02, -2.1323e-01,\n",
            "         -3.5798e-02, -2.1314e-01, -2.0939e-01, -1.3579e-01,  2.4380e-03,\n",
            "         -1.9178e-01, -1.0253e-01,  6.5330e-02, -1.8721e-01, -1.2524e-01,\n",
            "         -9.8325e-02,  1.2345e-01,  5.4014e-03, -1.4140e-01,  6.0079e-02],\n",
            "        [ 1.9298e-01, -2.3303e-02, -1.4652e-01,  2.0349e-01, -5.5213e-02,\n",
            "          2.8779e-03,  1.6749e-01, -2.0822e-01, -1.0585e-01, -1.2162e-01,\n",
            "          2.1457e-01, -9.0634e-02,  3.7379e-02, -3.1261e-02, -7.4346e-02,\n",
            "          1.3132e-02,  1.3683e-01,  1.5568e-01, -6.5263e-02,  4.6132e-02],\n",
            "        [-6.4381e-02, -1.5592e-01, -1.4899e-01, -1.4547e-01,  5.2735e-02,\n",
            "          1.6835e-01, -1.8006e-01, -7.7958e-02, -3.5797e-02,  1.0707e-01,\n",
            "         -9.6407e-02,  1.0772e-01, -1.5508e-01, -1.2767e-01, -1.5888e-02,\n",
            "         -1.8018e-01, -9.4223e-03, -7.9081e-02,  5.7901e-02,  4.6404e-02],\n",
            "        [-3.7831e-02, -5.1912e-02, -6.7251e-02, -9.5708e-02, -1.3979e-01,\n",
            "          7.2389e-02,  7.3692e-03, -1.0465e-04, -1.9722e-01, -1.8009e-01,\n",
            "          7.7234e-02,  2.0438e-01, -2.0472e-01,  3.0204e-02, -8.7263e-02,\n",
            "         -9.6604e-02, -2.0726e-01, -6.5497e-02,  1.9490e-02,  3.3275e-02],\n",
            "        [-1.5779e-02, -9.5539e-03,  5.2957e-02,  1.2335e-01,  3.7986e-02,\n",
            "         -1.0859e-01,  1.3025e-01,  9.2247e-02,  1.5550e-01,  4.4775e-02,\n",
            "         -1.7968e-01, -1.9388e-01, -4.4886e-02, -7.2322e-02, -1.2544e-03,\n",
            "          1.5586e-01,  2.1905e-01,  1.6471e-01, -2.1909e-01, -2.1435e-01]],\n",
            "       requires_grad=True))\n",
            "('l2.bias', Parameter containing:\n",
            "tensor([-0.1382, -0.0339, -0.1989,  0.1499,  0.2221,  0.1985, -0.1262, -0.1983,\n",
            "        -0.1433, -0.0256], requires_grad=True))\n",
            "('l3.weight', Parameter containing:\n",
            "tensor([[-0.0768, -0.0265,  0.2918, -0.1616,  0.2582, -0.2261,  0.0253,  0.0298,\n",
            "          0.0994, -0.0344],\n",
            "        [-0.2740,  0.2778, -0.1320, -0.2137, -0.2029, -0.2037, -0.2482,  0.0885,\n",
            "         -0.1486, -0.3134],\n",
            "        [ 0.3006,  0.1092, -0.2963,  0.1285, -0.0825, -0.0411,  0.0031, -0.0382,\n",
            "         -0.2618,  0.0508],\n",
            "        [-0.2275,  0.1726,  0.1039, -0.1591, -0.2843,  0.1055, -0.0866, -0.2517,\n",
            "          0.1110, -0.0351],\n",
            "        [ 0.0356,  0.3110,  0.2072, -0.0126, -0.1744, -0.1296,  0.0211,  0.0211,\n",
            "         -0.2874, -0.1343],\n",
            "        [ 0.2968,  0.2246, -0.1669,  0.1795, -0.0112, -0.1346,  0.3043,  0.2962,\n",
            "          0.1757, -0.2134]], requires_grad=True))\n",
            "('l3.bias', Parameter containing:\n",
            "tensor([ 0.1382, -0.2633,  0.2073, -0.0929,  0.1558,  0.0639],\n",
            "       requires_grad=True))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnzzaz1hxy16",
        "outputId": "16c5b5e6-c67b-4c68-a806-8c9b59a07887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (l1): Linear(in_features=11, out_features=20, bias=True)\n",
            "  (l2): Linear(in_features=20, out_features=10, bias=True)\n",
            "  (l3): Linear(in_features=10, out_features=6, bias=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HogSmfTuvZZE",
        "outputId": "b3de3c4b-f997-4d1b-ca9d-1f52bd0e633c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "Net                                      --\n",
              "├─Linear: 1-1                            240\n",
              "├─Linear: 1-2                            210\n",
              "├─Linear: 1-3                            66\n",
              "├─ReLU: 1-4                              --\n",
              "=================================================================\n",
              "Total params: 516\n",
              "Trainable params: 516\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 処理\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  \n",
        "  #-------------学習----------------\n",
        "  \n",
        "  # 勾配の初期化\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # 予測計算\n",
        "  outputs_train = net(inputs_train)\n",
        "\n",
        "  # 損失計算\n",
        "  loss = criterion(outputs_train, labels_train)\n",
        "\n",
        "  # 勾配計算\n",
        "  loss.backward()\n",
        "\n",
        "  # パラメータ修正\n",
        "  optimizer.step()\n",
        "\n",
        "  # 予測ラベル算出\n",
        "  # スコアが一番高いもの\n",
        "  predicated = torch.max(outputs_train, 1)[1]\n",
        "\n",
        "  # 損失と精度の計算\n",
        "  # 予測と実際の値が合っているものの合計をラベルの大きさで割れば、予測精度がわかる\n",
        "  train_loss = loss.item()\n",
        "  train_acc = (predicated == labels_train).sum()/len(labels_train)\n",
        "\n",
        "  #-------------予測----------------\n",
        "\n",
        "  # 予測計算\n",
        "  outputs_test = net(inputs_test)\n",
        "\n",
        "  # 損失計算\n",
        "  loss_test = criterion(outputs_test, labels_test)\n",
        "\n",
        "  # 予測ラベル算出\n",
        "  predicated_test = torch.max(outputs_test, 1)[1]\n",
        "\n",
        "  # 損失と精度の計算\n",
        "  val_loss = loss_test.item()\n",
        "  val_acc = (predicated_test == labels_test).sum()/len(labels_test)\n",
        "\n",
        "\n",
        "\n",
        "  # 記録\n",
        "  if((epoch) % 100 == 0):\n",
        "    print(f\"Epoch [{epoch}/{num_epochs}], loss:{train_loss:.5f} acc:{train_acc:.5f} val_loss: {val_loss:.5f} val_acc: {val_acc:.5f}\")\n",
        "    item = np.array([epoch, train_loss, train_acc, val_loss, val_acc])\n",
        "    history = np.vstack((history, item))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b46MaNJaM1X",
        "outputId": "e8916506-0ec0-4dbe-c0fd-6845a397d036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/20000], loss:44.76525 acc:0.00782 val_loss: 40.31724 val_acc: 0.00000\n",
            "Epoch [100/20000], loss:2.59337 acc:0.42611 val_loss: 2.85381 val_acc: 0.40938\n",
            "Epoch [200/20000], loss:2.22568 acc:0.42611 val_loss: 2.41257 val_acc: 0.40938\n",
            "Epoch [300/20000], loss:1.94740 acc:0.42611 val_loss: 2.07840 val_acc: 0.40938\n",
            "Epoch [400/20000], loss:1.73687 acc:0.42611 val_loss: 1.82588 val_acc: 0.40938\n",
            "Epoch [500/20000], loss:1.57814 acc:0.42611 val_loss: 1.63537 val_acc: 0.40938\n",
            "Epoch [600/20000], loss:1.39012 acc:0.45661 val_loss: 1.43390 val_acc: 0.44688\n",
            "Epoch [700/20000], loss:1.33541 acc:0.49023 val_loss: 1.36147 val_acc: 0.48750\n",
            "Epoch [800/20000], loss:1.29572 acc:0.49023 val_loss: 1.30963 val_acc: 0.51562\n",
            "Epoch [900/20000], loss:1.26582 acc:0.48319 val_loss: 1.27043 val_acc: 0.51250\n",
            "Epoch [1000/20000], loss:1.24338 acc:0.48632 val_loss: 1.24076 val_acc: 0.51250\n",
            "Epoch [1100/20000], loss:1.22645 acc:0.47928 val_loss: 1.21805 val_acc: 0.52812\n",
            "Epoch [1200/20000], loss:1.21347 acc:0.49257 val_loss: 1.20033 val_acc: 0.53438\n",
            "Epoch [1300/20000], loss:1.20328 acc:0.49492 val_loss: 1.18614 val_acc: 0.54688\n",
            "Epoch [1400/20000], loss:1.19513 acc:0.49257 val_loss: 1.17453 val_acc: 0.54062\n",
            "Epoch [1500/20000], loss:1.18850 acc:0.49726 val_loss: 1.16483 val_acc: 0.55000\n",
            "Epoch [1600/20000], loss:1.18304 acc:0.49883 val_loss: 1.15662 val_acc: 0.54688\n",
            "Epoch [1700/20000], loss:1.17852 acc:0.49726 val_loss: 1.14961 val_acc: 0.55000\n",
            "Epoch [1800/20000], loss:1.17478 acc:0.49805 val_loss: 1.14360 val_acc: 0.55000\n",
            "Epoch [1900/20000], loss:1.17168 acc:0.49805 val_loss: 1.13842 val_acc: 0.54375\n",
            "Epoch [2000/20000], loss:1.16913 acc:0.49414 val_loss: 1.13396 val_acc: 0.54062\n",
            "Epoch [2100/20000], loss:1.16703 acc:0.49257 val_loss: 1.13013 val_acc: 0.53438\n",
            "Epoch [2200/20000], loss:1.16531 acc:0.49023 val_loss: 1.12683 val_acc: 0.53438\n",
            "Epoch [2300/20000], loss:1.16392 acc:0.49257 val_loss: 1.12400 val_acc: 0.53438\n",
            "Epoch [2400/20000], loss:1.16278 acc:0.49335 val_loss: 1.12157 val_acc: 0.53438\n",
            "Epoch [2500/20000], loss:1.16186 acc:0.49101 val_loss: 1.11949 val_acc: 0.53125\n",
            "Epoch [2600/20000], loss:1.16112 acc:0.49023 val_loss: 1.11770 val_acc: 0.52812\n",
            "Epoch [2700/20000], loss:1.16051 acc:0.49101 val_loss: 1.11616 val_acc: 0.52812\n",
            "Epoch [2800/20000], loss:1.16001 acc:0.49179 val_loss: 1.11484 val_acc: 0.53125\n",
            "Epoch [2900/20000], loss:1.15960 acc:0.49023 val_loss: 1.11370 val_acc: 0.53750\n",
            "Epoch [3000/20000], loss:1.15926 acc:0.49023 val_loss: 1.11272 val_acc: 0.53750\n",
            "Epoch [3100/20000], loss:1.15898 acc:0.49257 val_loss: 1.11186 val_acc: 0.53438\n",
            "Epoch [3200/20000], loss:1.15874 acc:0.49257 val_loss: 1.11111 val_acc: 0.53438\n",
            "Epoch [3300/20000], loss:1.15854 acc:0.49335 val_loss: 1.11046 val_acc: 0.53438\n",
            "Epoch [3400/20000], loss:1.15836 acc:0.49257 val_loss: 1.10988 val_acc: 0.53438\n",
            "Epoch [3500/20000], loss:1.15821 acc:0.49414 val_loss: 1.10938 val_acc: 0.53750\n",
            "Epoch [3600/20000], loss:1.15808 acc:0.49414 val_loss: 1.10893 val_acc: 0.53750\n",
            "Epoch [3700/20000], loss:1.15797 acc:0.49414 val_loss: 1.10853 val_acc: 0.54062\n",
            "Epoch [3800/20000], loss:1.15787 acc:0.49335 val_loss: 1.10817 val_acc: 0.54062\n",
            "Epoch [3900/20000], loss:1.15778 acc:0.49335 val_loss: 1.10785 val_acc: 0.54062\n",
            "Epoch [4000/20000], loss:1.15770 acc:0.49335 val_loss: 1.10757 val_acc: 0.54062\n",
            "Epoch [4100/20000], loss:1.15762 acc:0.49335 val_loss: 1.10731 val_acc: 0.53750\n",
            "Epoch [4200/20000], loss:1.15756 acc:0.49414 val_loss: 1.10707 val_acc: 0.53750\n",
            "Epoch [4300/20000], loss:1.15750 acc:0.49492 val_loss: 1.10686 val_acc: 0.54062\n",
            "Epoch [4400/20000], loss:1.15744 acc:0.49570 val_loss: 1.10666 val_acc: 0.54062\n",
            "Epoch [4500/20000], loss:1.15739 acc:0.49648 val_loss: 1.10648 val_acc: 0.54062\n",
            "Epoch [4600/20000], loss:1.15735 acc:0.49648 val_loss: 1.10632 val_acc: 0.54062\n",
            "Epoch [4700/20000], loss:1.15731 acc:0.49726 val_loss: 1.10617 val_acc: 0.54062\n",
            "Epoch [4800/20000], loss:1.15727 acc:0.49648 val_loss: 1.10603 val_acc: 0.54062\n",
            "Epoch [4900/20000], loss:1.15723 acc:0.49648 val_loss: 1.10590 val_acc: 0.54062\n",
            "Epoch [5000/20000], loss:1.15720 acc:0.49648 val_loss: 1.10578 val_acc: 0.54062\n",
            "Epoch [5100/20000], loss:1.15716 acc:0.49648 val_loss: 1.10567 val_acc: 0.53750\n",
            "Epoch [5200/20000], loss:1.15713 acc:0.49648 val_loss: 1.10557 val_acc: 0.53750\n",
            "Epoch [5300/20000], loss:1.15710 acc:0.49726 val_loss: 1.10547 val_acc: 0.53750\n",
            "Epoch [5400/20000], loss:1.15708 acc:0.49570 val_loss: 1.10538 val_acc: 0.53750\n",
            "Epoch [5500/20000], loss:1.15705 acc:0.49570 val_loss: 1.10529 val_acc: 0.53750\n",
            "Epoch [5600/20000], loss:1.15702 acc:0.49570 val_loss: 1.10521 val_acc: 0.53750\n",
            "Epoch [5700/20000], loss:1.15700 acc:0.49570 val_loss: 1.10514 val_acc: 0.53750\n",
            "Epoch [5800/20000], loss:1.15697 acc:0.49570 val_loss: 1.10507 val_acc: 0.53750\n",
            "Epoch [5900/20000], loss:1.15695 acc:0.49570 val_loss: 1.10500 val_acc: 0.53750\n",
            "Epoch [6000/20000], loss:1.15693 acc:0.49492 val_loss: 1.10494 val_acc: 0.53750\n",
            "Epoch [6100/20000], loss:1.15690 acc:0.49492 val_loss: 1.10487 val_acc: 0.53750\n",
            "Epoch [6200/20000], loss:1.15688 acc:0.49492 val_loss: 1.10482 val_acc: 0.53750\n",
            "Epoch [6300/20000], loss:1.15686 acc:0.49492 val_loss: 1.10476 val_acc: 0.53750\n",
            "Epoch [6400/20000], loss:1.15684 acc:0.49492 val_loss: 1.10471 val_acc: 0.53750\n",
            "Epoch [6500/20000], loss:1.15682 acc:0.49492 val_loss: 1.10466 val_acc: 0.53750\n",
            "Epoch [6600/20000], loss:1.15680 acc:0.49492 val_loss: 1.10461 val_acc: 0.53750\n",
            "Epoch [6700/20000], loss:1.15678 acc:0.49492 val_loss: 1.10457 val_acc: 0.53750\n",
            "Epoch [6800/20000], loss:1.15676 acc:0.49492 val_loss: 1.10453 val_acc: 0.53750\n",
            "Epoch [6900/20000], loss:1.15674 acc:0.49492 val_loss: 1.10448 val_acc: 0.53750\n",
            "Epoch [7000/20000], loss:1.15672 acc:0.49570 val_loss: 1.10444 val_acc: 0.53750\n",
            "Epoch [7100/20000], loss:1.15670 acc:0.49570 val_loss: 1.10440 val_acc: 0.53750\n",
            "Epoch [7200/20000], loss:1.15668 acc:0.49570 val_loss: 1.10437 val_acc: 0.53750\n",
            "Epoch [7300/20000], loss:1.15667 acc:0.49570 val_loss: 1.10433 val_acc: 0.53750\n",
            "Epoch [7400/20000], loss:1.15665 acc:0.49570 val_loss: 1.10429 val_acc: 0.53750\n",
            "Epoch [7500/20000], loss:1.15663 acc:0.49570 val_loss: 1.10426 val_acc: 0.53750\n",
            "Epoch [7600/20000], loss:1.15661 acc:0.49570 val_loss: 1.10423 val_acc: 0.53750\n",
            "Epoch [7700/20000], loss:1.15659 acc:0.49570 val_loss: 1.10419 val_acc: 0.53750\n",
            "Epoch [7800/20000], loss:1.15657 acc:0.49570 val_loss: 1.10416 val_acc: 0.53750\n",
            "Epoch [7900/20000], loss:1.15655 acc:0.49570 val_loss: 1.10413 val_acc: 0.53750\n",
            "Epoch [8000/20000], loss:1.15654 acc:0.49570 val_loss: 1.10410 val_acc: 0.53750\n",
            "Epoch [8100/20000], loss:1.15652 acc:0.49570 val_loss: 1.10407 val_acc: 0.53750\n",
            "Epoch [8200/20000], loss:1.15650 acc:0.49570 val_loss: 1.10404 val_acc: 0.53750\n",
            "Epoch [8300/20000], loss:1.15648 acc:0.49492 val_loss: 1.10401 val_acc: 0.53750\n",
            "Epoch [8400/20000], loss:1.15646 acc:0.49492 val_loss: 1.10399 val_acc: 0.53750\n",
            "Epoch [8500/20000], loss:1.15645 acc:0.49492 val_loss: 1.10396 val_acc: 0.53750\n",
            "Epoch [8600/20000], loss:1.15643 acc:0.49492 val_loss: 1.10393 val_acc: 0.53750\n",
            "Epoch [8700/20000], loss:1.15641 acc:0.49492 val_loss: 1.10391 val_acc: 0.53750\n",
            "Epoch [8800/20000], loss:1.15639 acc:0.49414 val_loss: 1.10388 val_acc: 0.53750\n",
            "Epoch [8900/20000], loss:1.15638 acc:0.49414 val_loss: 1.10386 val_acc: 0.53750\n",
            "Epoch [9000/20000], loss:1.15636 acc:0.49414 val_loss: 1.10383 val_acc: 0.53750\n",
            "Epoch [9100/20000], loss:1.15634 acc:0.49414 val_loss: 1.10381 val_acc: 0.53750\n",
            "Epoch [9200/20000], loss:1.15632 acc:0.49414 val_loss: 1.10378 val_acc: 0.53750\n",
            "Epoch [9300/20000], loss:1.15631 acc:0.49492 val_loss: 1.10376 val_acc: 0.53750\n",
            "Epoch [9400/20000], loss:1.15629 acc:0.49492 val_loss: 1.10374 val_acc: 0.53750\n",
            "Epoch [9500/20000], loss:1.15627 acc:0.49492 val_loss: 1.10371 val_acc: 0.53750\n",
            "Epoch [9600/20000], loss:1.15625 acc:0.49570 val_loss: 1.10369 val_acc: 0.53750\n",
            "Epoch [9700/20000], loss:1.15624 acc:0.49570 val_loss: 1.10367 val_acc: 0.53750\n",
            "Epoch [9800/20000], loss:1.15622 acc:0.49570 val_loss: 1.10364 val_acc: 0.53750\n",
            "Epoch [9900/20000], loss:1.15620 acc:0.49570 val_loss: 1.10362 val_acc: 0.53750\n",
            "Epoch [10000/20000], loss:1.15619 acc:0.49570 val_loss: 1.10360 val_acc: 0.53750\n",
            "Epoch [10100/20000], loss:1.15617 acc:0.49570 val_loss: 1.10358 val_acc: 0.53750\n",
            "Epoch [10200/20000], loss:1.15615 acc:0.49570 val_loss: 1.10356 val_acc: 0.53750\n",
            "Epoch [10300/20000], loss:1.15613 acc:0.49414 val_loss: 1.10353 val_acc: 0.53750\n",
            "Epoch [10400/20000], loss:1.15612 acc:0.49414 val_loss: 1.10351 val_acc: 0.53750\n",
            "Epoch [10500/20000], loss:1.15610 acc:0.49414 val_loss: 1.10349 val_acc: 0.53750\n",
            "Epoch [10600/20000], loss:1.15608 acc:0.49414 val_loss: 1.10347 val_acc: 0.53750\n",
            "Epoch [10700/20000], loss:1.15606 acc:0.49492 val_loss: 1.10345 val_acc: 0.53750\n",
            "Epoch [10800/20000], loss:1.15605 acc:0.49492 val_loss: 1.10343 val_acc: 0.53750\n",
            "Epoch [10900/20000], loss:1.15603 acc:0.49492 val_loss: 1.10341 val_acc: 0.53750\n",
            "Epoch [11000/20000], loss:1.15601 acc:0.49492 val_loss: 1.10339 val_acc: 0.53750\n",
            "Epoch [11100/20000], loss:1.15599 acc:0.49492 val_loss: 1.10337 val_acc: 0.53750\n",
            "Epoch [11200/20000], loss:1.15598 acc:0.49492 val_loss: 1.10335 val_acc: 0.53750\n",
            "Epoch [11300/20000], loss:1.15596 acc:0.49492 val_loss: 1.10333 val_acc: 0.53750\n",
            "Epoch [11400/20000], loss:1.15594 acc:0.49492 val_loss: 1.10331 val_acc: 0.53750\n",
            "Epoch [11500/20000], loss:1.15593 acc:0.49492 val_loss: 1.10329 val_acc: 0.53750\n",
            "Epoch [11600/20000], loss:1.15591 acc:0.49492 val_loss: 1.10327 val_acc: 0.53750\n",
            "Epoch [11700/20000], loss:1.15589 acc:0.49492 val_loss: 1.10325 val_acc: 0.53750\n",
            "Epoch [11800/20000], loss:1.15587 acc:0.49492 val_loss: 1.10322 val_acc: 0.53750\n",
            "Epoch [11900/20000], loss:1.15586 acc:0.49492 val_loss: 1.10321 val_acc: 0.53750\n",
            "Epoch [12000/20000], loss:1.15584 acc:0.49492 val_loss: 1.10319 val_acc: 0.53750\n",
            "Epoch [12100/20000], loss:1.15582 acc:0.49492 val_loss: 1.10317 val_acc: 0.53750\n",
            "Epoch [12200/20000], loss:1.15581 acc:0.49492 val_loss: 1.10315 val_acc: 0.53750\n",
            "Epoch [12300/20000], loss:1.15579 acc:0.49492 val_loss: 1.10313 val_acc: 0.53750\n",
            "Epoch [12400/20000], loss:1.15577 acc:0.49492 val_loss: 1.10311 val_acc: 0.53750\n",
            "Epoch [12500/20000], loss:1.15575 acc:0.49492 val_loss: 1.10309 val_acc: 0.53750\n",
            "Epoch [12600/20000], loss:1.15574 acc:0.49492 val_loss: 1.10307 val_acc: 0.53750\n",
            "Epoch [12700/20000], loss:1.15572 acc:0.49492 val_loss: 1.10305 val_acc: 0.53750\n",
            "Epoch [12800/20000], loss:1.15570 acc:0.49492 val_loss: 1.10303 val_acc: 0.53750\n",
            "Epoch [12900/20000], loss:1.15569 acc:0.49492 val_loss: 1.10301 val_acc: 0.53750\n",
            "Epoch [13000/20000], loss:1.15567 acc:0.49492 val_loss: 1.10299 val_acc: 0.53750\n",
            "Epoch [13100/20000], loss:1.15565 acc:0.49492 val_loss: 1.10297 val_acc: 0.53750\n",
            "Epoch [13200/20000], loss:1.15563 acc:0.49492 val_loss: 1.10296 val_acc: 0.53750\n",
            "Epoch [13300/20000], loss:1.15562 acc:0.49492 val_loss: 1.10294 val_acc: 0.53750\n",
            "Epoch [13400/20000], loss:1.15560 acc:0.49492 val_loss: 1.10292 val_acc: 0.53750\n",
            "Epoch [13500/20000], loss:1.15558 acc:0.49492 val_loss: 1.10290 val_acc: 0.53750\n",
            "Epoch [13600/20000], loss:1.15557 acc:0.49492 val_loss: 1.10288 val_acc: 0.53750\n",
            "Epoch [13700/20000], loss:1.15555 acc:0.49492 val_loss: 1.10286 val_acc: 0.53750\n",
            "Epoch [13800/20000], loss:1.15553 acc:0.49492 val_loss: 1.10284 val_acc: 0.53750\n",
            "Epoch [13900/20000], loss:1.15552 acc:0.49492 val_loss: 1.10283 val_acc: 0.53750\n",
            "Epoch [14000/20000], loss:1.15550 acc:0.49492 val_loss: 1.10281 val_acc: 0.53750\n",
            "Epoch [14100/20000], loss:1.15548 acc:0.49492 val_loss: 1.10279 val_acc: 0.53750\n",
            "Epoch [14200/20000], loss:1.15546 acc:0.49492 val_loss: 1.10277 val_acc: 0.53750\n",
            "Epoch [14300/20000], loss:1.15545 acc:0.49492 val_loss: 1.10275 val_acc: 0.53750\n",
            "Epoch [14400/20000], loss:1.15543 acc:0.49492 val_loss: 1.10273 val_acc: 0.53750\n",
            "Epoch [14500/20000], loss:1.15541 acc:0.49492 val_loss: 1.10272 val_acc: 0.53750\n",
            "Epoch [14600/20000], loss:1.15540 acc:0.49648 val_loss: 1.10270 val_acc: 0.53750\n",
            "Epoch [14700/20000], loss:1.15538 acc:0.49648 val_loss: 1.10268 val_acc: 0.53750\n",
            "Epoch [14800/20000], loss:1.15536 acc:0.49648 val_loss: 1.10266 val_acc: 0.53750\n",
            "Epoch [14900/20000], loss:1.15535 acc:0.49648 val_loss: 1.10264 val_acc: 0.53750\n",
            "Epoch [15000/20000], loss:1.15533 acc:0.49648 val_loss: 1.10262 val_acc: 0.53750\n",
            "Epoch [15100/20000], loss:1.15531 acc:0.49648 val_loss: 1.10260 val_acc: 0.53438\n",
            "Epoch [15200/20000], loss:1.15529 acc:0.49648 val_loss: 1.10259 val_acc: 0.53438\n",
            "Epoch [15300/20000], loss:1.15528 acc:0.49648 val_loss: 1.10257 val_acc: 0.53438\n",
            "Epoch [15400/20000], loss:1.15526 acc:0.49648 val_loss: 1.10255 val_acc: 0.53438\n",
            "Epoch [15500/20000], loss:1.15524 acc:0.49648 val_loss: 1.10253 val_acc: 0.53438\n",
            "Epoch [15600/20000], loss:1.15523 acc:0.49648 val_loss: 1.10251 val_acc: 0.53438\n",
            "Epoch [15700/20000], loss:1.15521 acc:0.49648 val_loss: 1.10249 val_acc: 0.53438\n",
            "Epoch [15800/20000], loss:1.15519 acc:0.49648 val_loss: 1.10248 val_acc: 0.53438\n",
            "Epoch [15900/20000], loss:1.15518 acc:0.49648 val_loss: 1.10246 val_acc: 0.53438\n",
            "Epoch [16000/20000], loss:1.15516 acc:0.49648 val_loss: 1.10244 val_acc: 0.53438\n",
            "Epoch [16100/20000], loss:1.15514 acc:0.49648 val_loss: 1.10242 val_acc: 0.53438\n",
            "Epoch [16200/20000], loss:1.15513 acc:0.49648 val_loss: 1.10240 val_acc: 0.53438\n",
            "Epoch [16300/20000], loss:1.15511 acc:0.49648 val_loss: 1.10239 val_acc: 0.53438\n",
            "Epoch [16400/20000], loss:1.15509 acc:0.49648 val_loss: 1.10237 val_acc: 0.53438\n",
            "Epoch [16500/20000], loss:1.15508 acc:0.49648 val_loss: 1.10235 val_acc: 0.53438\n",
            "Epoch [16600/20000], loss:1.15506 acc:0.49648 val_loss: 1.10233 val_acc: 0.53438\n",
            "Epoch [16700/20000], loss:1.15504 acc:0.49648 val_loss: 1.10231 val_acc: 0.53438\n",
            "Epoch [16800/20000], loss:1.15503 acc:0.49648 val_loss: 1.10229 val_acc: 0.53438\n",
            "Epoch [16900/20000], loss:1.15501 acc:0.49648 val_loss: 1.10228 val_acc: 0.53438\n",
            "Epoch [17000/20000], loss:1.15499 acc:0.49648 val_loss: 1.10226 val_acc: 0.53438\n",
            "Epoch [17100/20000], loss:1.15498 acc:0.49648 val_loss: 1.10224 val_acc: 0.53438\n",
            "Epoch [17200/20000], loss:1.15496 acc:0.49648 val_loss: 1.10222 val_acc: 0.53438\n",
            "Epoch [17300/20000], loss:1.15494 acc:0.49648 val_loss: 1.10220 val_acc: 0.53438\n",
            "Epoch [17400/20000], loss:1.15493 acc:0.49805 val_loss: 1.10218 val_acc: 0.53438\n",
            "Epoch [17500/20000], loss:1.15491 acc:0.49805 val_loss: 1.10217 val_acc: 0.53438\n",
            "Epoch [17600/20000], loss:1.15489 acc:0.49805 val_loss: 1.10215 val_acc: 0.53438\n",
            "Epoch [17700/20000], loss:1.15488 acc:0.49805 val_loss: 1.10213 val_acc: 0.53438\n",
            "Epoch [17800/20000], loss:1.15486 acc:0.49805 val_loss: 1.10211 val_acc: 0.53438\n",
            "Epoch [17900/20000], loss:1.15484 acc:0.49805 val_loss: 1.10209 val_acc: 0.53438\n",
            "Epoch [18000/20000], loss:1.15483 acc:0.49805 val_loss: 1.10208 val_acc: 0.53438\n",
            "Epoch [18100/20000], loss:1.15481 acc:0.49805 val_loss: 1.10206 val_acc: 0.53438\n",
            "Epoch [18200/20000], loss:1.15479 acc:0.49805 val_loss: 1.10204 val_acc: 0.53438\n",
            "Epoch [18300/20000], loss:1.15478 acc:0.49805 val_loss: 1.10202 val_acc: 0.53438\n",
            "Epoch [18400/20000], loss:1.15476 acc:0.49805 val_loss: 1.10200 val_acc: 0.53438\n",
            "Epoch [18500/20000], loss:1.15474 acc:0.49805 val_loss: 1.10199 val_acc: 0.53438\n",
            "Epoch [18600/20000], loss:1.15473 acc:0.49805 val_loss: 1.10197 val_acc: 0.53438\n",
            "Epoch [18700/20000], loss:1.15471 acc:0.49805 val_loss: 1.10195 val_acc: 0.53438\n",
            "Epoch [18800/20000], loss:1.15469 acc:0.49805 val_loss: 1.10193 val_acc: 0.53438\n",
            "Epoch [18900/20000], loss:1.15468 acc:0.49805 val_loss: 1.10191 val_acc: 0.53438\n",
            "Epoch [19000/20000], loss:1.15466 acc:0.49805 val_loss: 1.10190 val_acc: 0.53438\n",
            "Epoch [19100/20000], loss:1.15464 acc:0.49805 val_loss: 1.10188 val_acc: 0.53438\n",
            "Epoch [19200/20000], loss:1.15463 acc:0.49805 val_loss: 1.10186 val_acc: 0.53438\n",
            "Epoch [19300/20000], loss:1.15461 acc:0.49805 val_loss: 1.10184 val_acc: 0.53438\n",
            "Epoch [19400/20000], loss:1.15459 acc:0.49805 val_loss: 1.10183 val_acc: 0.53438\n",
            "Epoch [19500/20000], loss:1.15458 acc:0.49805 val_loss: 1.10181 val_acc: 0.53438\n",
            "Epoch [19600/20000], loss:1.15456 acc:0.49805 val_loss: 1.10179 val_acc: 0.53438\n",
            "Epoch [19700/20000], loss:1.15454 acc:0.49805 val_loss: 1.10177 val_acc: 0.53438\n",
            "Epoch [19800/20000], loss:1.15453 acc:0.49805 val_loss: 1.10176 val_acc: 0.53438\n",
            "Epoch [19900/20000], loss:1.15451 acc:0.49805 val_loss: 1.10174 val_acc: 0.53438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#損失と精度の確認\n",
        "\n",
        "print(f'初期状態: 損失: {history[0,3]:.5f} 精度: {history[0,4]:.5f}' )\n",
        "print(f'最終状態: 損失: {history[-1,3]:.5f} 精度: {history[-1,4]:.5f}' )"
      ],
      "metadata": {
        "id": "OTJz4MQ1tjMV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8bdb76d-da8b-48b7-825d-40db1c5979c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "初期状態: 損失: 40.31724 精度: 0.00000\n",
            "最終状態: 損失: 1.10174 精度: 0.53438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習曲線の表示 (損失)\n",
        "\n",
        "plt.plot(history[:,0], history[:,1], 'b', label='訓練')\n",
        "plt.plot(history[:,0], history[:,3], 'k', label='検証')\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('損失')\n",
        "plt.title('学習曲線(損失)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "8d2J6O1ttPJ-",
        "outputId": "fe228426-e4ad-4461-a643-605377bfaac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習曲線の表示 (精度)\n",
        "\n",
        "plt.plot(history[:,0], history[:,2], 'b', label='訓練')\n",
        "plt.plot(history[:,0], history[:,4], 'k', label='検証')\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('精度')\n",
        "plt.title('学習曲線(精度)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "P--DdOkptSGD",
        "outputId": "14ff6575-f4bc-4546-f55f-a0aecb652f22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}